# -*- coding: utf-8 -*-
"""preprocessing.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1bY6BGHXrXXuQyzDLO6C_0DvxF949Gcbo
"""

import torch
import torchvision.transforms as T
from torchvision import models

import numpy as np
import matplotlib.pyplot as plt

import cv2
from PIL import Image

import functools

@functools.lru_cache(maxsize=1)
def get_segmentation_model(name="deeplabv3_resnet101"):
    """
    Load a segmentation model by name and cache it.

    Args:
        name (str): Model name. Supported:
            - 'deeplabv3_resnet101'
            - 'deeplabv3_mobilenet_v3_large'
            - 'fcn_resnet50'

    Returns:
        torch.nn.Module: Segmentation model in eval mode on proper device.
    """
    name = name.lower()
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

    if name == "deeplabv3_resnet101":
        model = models.segmentation.deeplabv3_resnet101(pretrained=True)
    elif name == "deeplabv3_mobilenet_v3_large":
        model = models.segmentation.deeplabv3_mobilenet_v3_large(pretrained=True)
    elif name == "fcn_resnet50":
        model = models.segmentation.fcn_resnet50(pretrained=True)
    else:
        raise ValueError(f"Unsupported model name: {name}")

    model.to(device)
    model.eval()
    return model

def segment_and_crop_character(image_input, target_class, n_elements=1, model_name="deeplabv3_resnet101"):
    """
    Segment and crop the largest object of a specific class in the image.

    Args:
        image_input (str or np.ndarray): Path to image or BGR image array.
        target_class (int): Class ID to extract (e.g., 12 = dog, 15 = person).

    Returns:
        binarized (np.ndarray): Grayscale binarized and blurred image [0-255].
        cropped_mask (np.ndarray): Binary mask [0, 255] of the cropped object.
        cropped_rgb (np.ndarray): RGB cropped image of the detected object.
    """

    #load image if path is provide
    if isinstance(image_input, str):
        img = cv2.imread(image_input)
    else:
        img_rgb = image_input.copy()

    img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
    img_pil = Image.fromarray(img_rgb)

    #Preprocess for DeepLabv3
    transform = T.Compose([
        T.ToTensor(),
        T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])])

    input_tensor = transform(img_pil).unsqueeze(0)

    #load model (cached)
    model = get_segmentation_model(model_name)
    device = next(model.parameters()).device

    input_tensor = input_tensor.to(device)

    #Inference
    with torch.no_grad():
        output = model(input_tensor)['out'][0]
        output_predictions = output.argmax(0).cpu().numpy()

    #Create binary mask for target class
    mask = np.isin(output_predictions, target_class).astype(np.uint8)

    #Find the largest component
    num_labels, labels, stats, _ = cv2.connectedComponentsWithStats(mask, connectivity=8)

    #Skip background
    if num_labels <= 1:
        raise Exception("No connected regions found.")

    # Get areas and sort by size (exclude background at index 0)
    areas = stats[1:, cv2.CC_STAT_AREA]
    sorted_indices = np.argsort(areas)[::-1]
    selected_labels = 1 + sorted_indices[:n_elements]


    # Create final mask with top-n components
    final_mask = np.isin(labels, selected_labels).astype(np.uint8)

    #Get bounding box around all selected components
    ys, xs = np.where(final_mask == 1)
    x, y, w, h = xs.min(), ys.min(), xs.max() - xs.min() + 1, ys.max() - ys.min() + 1

    # Crop regions
    cropped_rgb = img_rgb[y:y+h, x:x+w]
    cropped_mask = (final_mask[y:y+h, x:x+w] * 255).astype(np.uint8)

    # Convert to grayscale
    cropped_gray = cv2.cvtColor(cropped_rgb, cv2.COLOR_RGB2GRAY)

    # Apply Gaussian Blur
    blurred = cv2.GaussianBlur(cropped_gray, (5, 5), 0)

    #Binarized image
    binary_cropped = cv2.adaptiveThreshold(
    blurred, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C,
    cv2.THRESH_BINARY_INV, 11, 2)

    if cropped_mask.shape != binary_cropped.shape:
      binary_cropped = cv2.resize(binary_cropped, (cropped_mask.shape[1], cropped_mask.shape[0]))

    #Apply mask to binarized image
    result = cv2.bitwise_and(cropped_mask, binary_cropped)

    return result, cropped_mask, cropped_rgb